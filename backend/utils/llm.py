import os
from dotenv import load_dotenv
from google import genai

load_dotenv()

client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

def generate_answer(context, query):
    try:
        prompt = f"""
        Answer ONLY using this context:

        Context:
        {context}

        Question:
        {query}
        """

        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt
        )

        return response.text

    except Exception as e:
        return f"LLM Error: {str(e)}"